# -*- coding: utf-8 -*-
"""DNLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iI3hDv215jm6xKzxNHmb5ONLM5Fx5kqY

##Sentiment Analysis using DNLP
"""

import numpy as np
import pandas as pd

df= pd.read_csv('train.csv')
df=df.drop(columns=['url','host','qa_id','question_user_name','question_user_page','answer_user_name','answer_user_page'])
#df['average answer points']=round((df['answer_helpful']+df['answer_level_of_information']+df['answer_relevance']+df['answer_type_procedure']+df['answer_type_reason_explanation']+df['answer_well_written']+df['answer_plausible']+df['answer_satisfaction']+df['answer_type_instructions'])/9)
df=df.drop(columns=['answer_helpful','answer_level_of_information','answer_relevance','answer_type_procedure','answer_type_reason_explanation','answer_well_written','answer_type_instructions','answer_satisfaction','answer_plausible'])
#df['average question points']=round((df['question_asker_intent_understanding']+df['question_body_critical']+df['question_conversational']+df['question_expect_short_answer']+df['question_fact_seeking']+df['question_has_commonly_accepted_answer']+df['question_interestingness_others']+df['question_interestingness_self']+df['question_multi_intent']+df['question_not_really_a_question']+df['question_opinion_seeking']+df['question_type_choice']+df['question_type_compare']+df['question_type_consequence']+df['question_type_definition']+df['question_type_entity']+df['question_type_instructions']+df['question_type_procedure']+df['question_type_reason_explanation']+df['question_type_spelling']+df['question_well_written'])/21)
df=df.drop(columns=['question_title','answer','question_asker_intent_understanding','question_body_critical','question_conversational','question_expect_short_answer','question_expect_short_answer','question_fact_seeking','question_has_commonly_accepted_answer','question_interestingness_others','question_interestingness_self','question_multi_intent','question_not_really_a_question','question_opinion_seeking','question_type_choice','question_type_compare','question_type_consequence','question_type_definition','question_type_entity','question_type_instructions','question_type_procedure','question_type_reason_explanation','question_type_spelling','question_well_written'])
df=df.dropna(how='any')
df

df['category'].unique()

from sklearn.preprocessing import LabelEncoder
label_encoder = LabelEncoder()
df['category']= label_encoder.fit_transform(df['category']) 
df['category'].unique()

import re
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
corpus = []
corpus1=[]
corpus2=[]
for i in range(0, 6079):
  review = re.sub('[^a-zA-Z]', ' ', df['question_body'][i])
  review = review.lower()
  review = review.split()
  ps = PorterStemmer()
  all_stopwords = stopwords.words('english')
  all_stopwords.remove('not')
  review = [ps.stem(word) for word in review if not word in set(all_stopwords)]
  review = ' '.join(review)
  corpus.append(review)

print(corpus)

from sklearn.feature_extraction.text import CountVectorizer
cv = CountVectorizer(max_features = 1500)
X = cv.fit_transform(corpus).toarray()
y=df.iloc[:,-1].values

X[:1,:]

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)

"""## Neural Network  Implementation"""

import tensorflow as tf
from sklearn.model_selection import train_test_split

classs = { 1:"CULTURE",
           2:"LIFE_ARTS",
           3:"SCIENCE",
           4:"STACKOVERFLOW",
           5:"TECHNOLOGY"
           }

y_train = tf.keras.utils.to_categorical(y_train,5)
y_test = tf.keras.utils.to_categorical(y_test,5)

print("Initialized model")
ann = tf.keras.models.Sequential()
ann.add(tf.keras.layers.Dense(units=20, activation='relu'))
ann.add(tf.keras.layers.Dense(units=20, activation='relu'))
ann.add(tf.keras.layers.Dense(units=5, activation='softmax'))

ann.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
history = ann.fit(X_train, y_train, batch_size=15, epochs=10, validation_data=(X_test, y_test))
ann.save("DNLP.h5")

plt.figure(0)
plt.plot(history.history['accuracy'], label='training accuracy')
plt.plot(history.history['val_accuracy'], label='val accuracy')
plt.title('Accuracy')
plt.xlabel('epochs')
plt.ylabel('accuracy')
plt.legend()
plt.savefig('Accuracy.png')

plt.figure(1)
plt.plot(history.history['loss'], label='training loss')
plt.plot(history.history['val_loss'], label='val loss')
plt.title('Loss')
plt.xlabel('epochs')
plt.ylabel('loss')
plt.legend()
plt.savefig('Loss.png')
print("Saved Model & Graph to disk")

model = tf.keras.models.load_model('DNLP.h5')
print("Loaded model from disk")
test=[[X[5:6,:]]]
result = model.predict_classes(test)[0]
cat= classs[result + 1]
print("The category for the same is {}".format(cat))